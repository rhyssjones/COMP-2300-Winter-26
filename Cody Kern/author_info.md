---

title: "Cody Kern"
date: 2026-01-16
publish: false
tags:
  - profile
  - contributor
---

# Cody Kern

## Op-Ed

AI: Hidden Opportunities 
As we start to work our way through another revolution, it is natural to feel a bit uneasy. 
Similar feelings arose in every revolution that we, as a species, have been through up until now. 
It is simply human nature; what a lot of us feel currently watching things become more 
autonomous. It happened during the industrial revolution as well. Though, one thing I would like 
to point out is that we have also learned to adapt to these revolutions and learned to live with 
them. Impact on Society During the Industrial Revolution  
If we look at the history of our media, it is not hard to see why it would be something we 
have learned to fear. Movies like ‘The Matrix’ and ‘Eagle-Eye’ show us what happens when 
Artificial Intelligence gets way to out of hand. Something that should be kept in mind is the 
difference between Artificial Intelligence and Sentience. The AI that we use to automate our 
everyday life seems like it has all the elements of intelligence, but it just simply is not. In fact, 
the biggest need that should be the point of concentration is the need for some sort of regulation 
on it to stop companies from pushing out every automated service they possibly can.  
Not only is this the main cause of concern for the environment, but also for the type of 
information that is being dispersed. Two examples of not having regulations are AWS and IBM; 
both companies are leading suppliers of AI-driven technologies AI Chat Builder - Amazon Lex - 
AWS. Offering AI chatbots at a commercial level. Promoting convenience while neglecting 
information about the impact of water usage and offering another alternative. Something that 
could become more common if there isn’t a regulation. 
As we can see in the table above, unregulated AI usage is a problem and it appears that 
China’s president Xi Jinping, has been the first to propose a global regulation AI hub in 
Shanghai. Without proper regulation of AI, we will continue to see AI fail to live up to its 
potential. Even less, if companies just see it as an easy way to minimize costs and maximize 
profit.  
A Brief History of Large Language Models - Dataversity Artificial Intelligence uses what 
is called a Large Language Model, and has been used by the government since as far back as the 
50’s. With the first chatbot around 1966, these models inherited human biases. Meaning that a lot 
of the misconceptions that have been developed over humans' existence have also been coded 
into these models. This would only go to show just how easily information, and quite frankly AI 
in general, could continue to become just another useless tool that ends up being more like the 
movie ‘Idiocracy’.  
The best and most important thing to prevent a future is that we are overly reliant on AI. 
We should be pushing for full support of AI regulation, from all levels of the AI community. 
This includes lawmakers; regulation could, in fact, calm a lot of the concerns surrounding the 
level to which people are using AI. We should be teaching people how to use AI critically and 
learn how to collaborate with technology and information. Instead of trying to use it to further 
the gap between classes. 
If we consider communities that may not have access to information outside of an 
internet connection, AI gives information to those communities. However, the importance should 
not be on the abandonment of AI. Instead, the focus of AI should be on making it the best 
version possible. According to The Commonwealth Institute’s article ‘Unequal Opportunities’ 
students in Virginia’s High Poverty, areas only have access to a third of fully accredited schools 
that offer the proper courses. Compared to Low Poverty students where almost all schools are 
fully accredited by the state.  
It’s important to remember to also not become overly reliant on it, as this could continue 
to push the state of AI further away from what makes it truly a powerful tool. That is, if we can 
push for a more regulated form of AI. So that we can teach it, and it can teach us, creating a more 
collaborative environment. Connecting information from the world's greatest minds to higher 
poverty areas. Eventually, we could use it as a collaboration partner and could even learn to 
create a more balanced, unbiased justice system, or a fair, equal health care system. 
This would require what is known as Artificial Generative Intelligence. Which would still 
be a far-off expectation with the current state. Currently, Artificial Intelligence will only be as 
smart and capable as the information that is provided to it. Until then, it is important to 
understand how to use AI to teach you rather than having it solve the problem for you. 

## Focus

AI can potentially help close the gap that is seen between high-poverty/low-poverty. If we use the examples of how we have had AI in our media
and learn from those mistakes. For this to happen, we need to start considering the need to have a regulation set on who can distribute what
types of AI. Forcing leading producers of AI services, such as AWS and IBM, to put out better and more efficient systems. While looking
for other alternatives to take some of the pressure off the data centers.

## Media sample

![Moody hallway scene from a stock photo](https://images.unsplash.com/photo-1470770903676-69b98201ea1c?auto=format&fit=crop&w=1200&q=80){ .post-photo }
](https://www.dropbox.com/scl/fi/yz3u7ej4lxjngmvm22etj/Coding.jpg?rlkey=0nhyn5x8leb3e30ztlaujfpbw&st=r3e6smje&dl=0){ .post-photo }


Photo credit: Unsplash

## Links

- Starter post: starter_post.md
- Video link: https://www.youtube.com/watch?v=LXb3EKWsInQ
